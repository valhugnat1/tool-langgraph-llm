{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag.py file\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Establish connection to PostgreSQL database using environment variables\n",
    "conn = psycopg2.connect(\n",
    "    database=os.getenv(\"PGDATABASE\"),\n",
    "    user=os.getenv(\"PGUSER\"),\n",
    "    password=os.getenv(\"PGPASSWORD\"),\n",
    "    host=os.getenv(\"PGHOST\"),\n",
    "    port=os.getenv(\"PGPORT\"),\n",
    ")\n",
    "\n",
    "\n",
    "# Create a cursor to execute SQL commands\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'healthy', 'database': 'connected'}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"SELECT 1\")\n",
    "    print({\"status\": \"healthy\", \"database\": \"connected\"})\n",
    "except Exception as e:\n",
    "    print({\"status\": \"unhealthy\", \"database\": str(e)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=os.getenv(\"SCW_SECRET_KEY\"),\n",
    "    openai_api_base=os.getenv(\"SCW_GENERATIVE_APIs_ENDPOINT\"),\n",
    "    model=\"sentence-transformers/sentence-t5-xxl\",\n",
    "    tiktoken_enabled=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_postgres import PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = f\"postgresql+psycopg2://{conn.info.user}:{conn.info.password}@{conn.info.host}:{conn.info.port}/{conn.info.dbname}\"\n",
    "vector_store = PGVector(connection=connection_string, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vector_db = Chroma(...)\n",
    "docs = vector_db.get()\n",
    "documents = docs[\"documents\"]\n",
    "\n",
    "vector_retriever = vector_db.as_retriever(...)\n",
    "keyword_retriever = BM25Retriever.from_texts(documents)\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[keyword_retriever, vector_retriever], ...)\n",
    "\n",
    "In details:\n",
    "\n",
    "Import the libraries:\n",
    "\n",
    "from langchain_chroma import Chroma # Langchain\n",
    "import chromadb # Chroma\n",
    "\n",
    "Instantiate the Chroma vector DB:\n",
    "\n",
    "chroma_client = chromadb.HttpClient(host=CHROMA_SERVER_HOST, port=CHROMA_SERVER_PORT)\n",
    "vector_db = Chroma(embedding_function=embedding_model, collection_name=COLLECTION_NAME, client=chroma_client)\n",
    "docs = vector_db.get()\n",
    "documents = docs[\"documents\"]\n",
    "\n",
    "RAG hybrid search (same code for Chroma or PostgreSQL):\n",
    "\n",
    "vector_retriever = vector_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": VECTORDB_MAX_RESULTS}) # Semantic search\n",
    "keyword_retriever = BM25Retriever.from_texts(documents) # Keyword search\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[keyword_retriever, vector_retriever], weights=[0.5, 0.5]) # Combining the two searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag.py\n",
    "\n",
    "import boto3\n",
    "from langchain_community.document_loaders import S3FileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag.py\n",
    "\n",
    "session = boto3.session.Session()\n",
    "client_s3 = session.client(\n",
    "    service_name=\"s3\",\n",
    "    endpoint_url=os.getenv(\"SCW_BUCKET_ENDPOINT\", \"\"),\n",
    "    aws_access_key_id=os.getenv(\"SCW_ACCESS_KEY\", \"\"),\n",
    "    aws_secret_access_key=os.getenv(\"SCW_SECRET_KEY\", \"\"),\n",
    ")\n",
    "paginator = client_s3.get_paginator(\"list_objects_v2\")\n",
    "page_iterator = paginator.paginate(Bucket=os.getenv(\"SCW_BUCKET_NAME\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_prompt(document_content, chunk_text):\n",
    "    \"\"\"\n",
    "    Creates a well-structured prompt for context generation.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_template = \"\"\"Here is the chunk we want to situate within the whole document \n",
    "<document>\n",
    "{document}\n",
    "</document>\n",
    "\n",
    "<chunk_to_analyze>\n",
    "{chunk}\n",
    "</chunk_to_analyze>\n",
    "Please give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk. Answer only with the succinct context and nothing else. \n",
    ".\"\"\"\n",
    "\n",
    "    return prompt_template.format(\n",
    "        document=document_content.strip(), chunk=chunk_text.strip()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<botocore.paginate.PageIterator at 0x122ad1a50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrivee_scw/bienvenue.txt\n",
      "This chunk is situated within the \"Bienvenue\" section of the document, specifically within the subsection titled \"# Programme d'onboarding\", which outlines the onboarding process for new employees at Scaleway.\n",
      "This chunk appears to be a section of the onboarding process for new employees at Scaleway, specifically detailing the first day of orientation and providing an overview of the company's HR department and resources.\n",
      "This chunk appears to be a section within the \"Bienvenue\" document, specifically under the \"Qui sommes nous?\" and \"Notre architecture humaine\" sections, providing an overview of Scaleway's internal structure, culture, and benefits for employees.\n",
      "This chunk appears to be part of the \"Qui sommes nous?\" section, which is a subsection of the \"Scaleway\" introduction, likely located near the beginning of the document.\n",
      "This chunk describes the organizational structure and human resources management system of Scaleway, including its departments, leadership, and tools such as Lucca and TIMMI.\n",
      "This chunk is situated within the \"La Direction des Ressources Humaines\" section of the document, which provides information about the Human Resources department and its tools and processes.\n",
      "This chunk is situated within the \"La Direction des Ressources Humaines\" section of the document, which provides information about the Human Resources department and its services at Scaleway.\n",
      "This chunk is situated within the \"Direction des Ressources Humaines\" section of the document, which provides information about the Human Resources department and its team members.\n",
      "This chunk is situated within the \"Bienvenue\" section of the document, specifically under the subheadings related to employee benefits and company facilities.\n",
      "This chunk is situated within the \"Bienvenue chez Scaleway\" document, specifically within the section titled \"Accords d'entreprise et avantages sociaux\".\n",
      "This chunk appears in the \"Bienvenue\" section of the document, specifically under the subheadings \"Freebox et avantages sociaux\" and \"La sécurité\", and also mentions \"All Hands\", which is a separate section.\n",
      "This chunk is situated within the \"Bienvenue chez Scaleway\" document, specifically within the section titled \"# All Hands\" and \"# Slack\", which describes the company's internal communication tools and processes.\n",
      "This chunk is situated within the \"Slack\" section of the document, which is part of the \"Bienvenue chez Scaleway\" onboarding process.\n",
      "This chunk is situated within the \"Collaboration Tools\" section of the document, specifically under the sub-sections \"Slack\" and \"Confluence\".\n",
      "The chunk is situated within the \"Confluence\" section of the document, which is located under the \"Slack\" section and is part of the \"All\" category.\n",
      "The chunk is part of a section explaining the features and functionality of Confluence, a knowledge base and collaboration tool used internally by Scaleway.\n",
      "Formation et Développement\n"
     ]
    }
   ],
   "source": [
    "# rag.py\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialize the client with your base URL and API key\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.scaleway.ai/v1\", api_key=os.getenv(\"SCW_SECRET_KEY\", \"\")\n",
    ")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=300,\n",
    "    add_start_index=True,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "for page in page_iterator:\n",
    "    for obj in page.get(\"Contents\", []):\n",
    "        if obj[\"Key\"] == \"arrivee_scw/bienvenue.txt\":\n",
    "            # Check if cursor is closed and reopen if necessary\n",
    "            if cur.closed:\n",
    "                cur = conn.cursor()\n",
    "\n",
    "            cur.execute(\n",
    "                \"SELECT object_key FROM object_loaded WHERE object_key = %s\",\n",
    "                (obj[\"Key\"],),\n",
    "            )\n",
    "            print(obj[\"Key\"])\n",
    "            response = cur.fetchone()\n",
    "            if response is None:\n",
    "                file_loader = S3FileLoader(\n",
    "                    bucket=os.getenv(\"SCW_BUCKET_NAME\", \"\"),\n",
    "                    key=obj[\"Key\"],\n",
    "                    endpoint_url=os.getenv(\"SCW_BUCKET_ENDPOINT\", \"\"),\n",
    "                    aws_access_key_id=os.getenv(\"SCW_ACCESS_KEY\", \"\"),\n",
    "                    aws_secret_access_key=os.getenv(\"SCW_SECRET_KEY\", \"\"),\n",
    "                )\n",
    "                file_to_load = file_loader.load()\n",
    "                doc = file_to_load[0].page_content\n",
    "                chunks = text_splitter.split_text(doc)\n",
    "                context_chunks = []\n",
    "\n",
    "                doc = \"Page title: \" + obj[\"Key\"] + \"\\n\" + doc\n",
    "\n",
    "                for chunk in chunks:\n",
    "                    completion = client.chat.completions.create(\n",
    "                        model=\"llama-3.1-8b-instruct\",\n",
    "                        messages=[\n",
    "                            {\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": create_context_prompt(\n",
    "                                    document_content=doc, chunk_text=chunk\n",
    "                                ),\n",
    "                            }\n",
    "                        ],\n",
    "                        temperature=0.1,\n",
    "                        max_tokens=100,\n",
    "                    )\n",
    "                    print(completion.choices[0].message.content)\n",
    "                    context_chunks.append(completion.choices[0].message.content + chunk)\n",
    "\n",
    "                try:\n",
    "                    embeddings_list = [\n",
    "                        embeddings.embed_query(chunk) for chunk in context_chunks\n",
    "                    ]\n",
    "                    vector_store.add_embeddings(chunks, embeddings_list)\n",
    "                    cur.execute(\n",
    "                        \"INSERT INTO object_loaded (object_key) VALUES (%s)\",\n",
    "                        (obj[\"Key\"],),\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
