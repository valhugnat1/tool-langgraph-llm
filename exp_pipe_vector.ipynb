{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag.py file\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Establish connection to PostgreSQL database using environment variables\n",
    "conn = psycopg2.connect(\n",
    "    database=os.getenv(\"PGDATABASE\"),\n",
    "    user=os.getenv(\"PGUSER\"),\n",
    "    password=os.getenv(\"PGPASSWORD\"),\n",
    "    host=os.getenv(\"PGHOST\"),\n",
    "    port=os.getenv(\"PGPORT\"),\n",
    ")\n",
    "\n",
    "\n",
    "# Create a cursor to execute SQL commands\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'healthy', 'database': 'connected'}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"SELECT 1\")\n",
    "    print({\"status\": \"healthy\", \"database\": \"connected\"})\n",
    "except Exception as e:\n",
    "    print({\"status\": \"unhealthy\", \"database\": str(e)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=os.getenv(\"SCW_SECRET_KEY\"),\n",
    "    openai_api_base=os.getenv(\"SCW_GENERATIVE_APIs_ENDPOINT\"),\n",
    "    model=\"sentence-transformers/sentence-t5-xxl\",\n",
    "    tiktoken_enabled=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_postgres import PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = f\"postgresql+psycopg2://{conn.info.user}:{conn.info.password}@{conn.info.host}:{conn.info.port}/{conn.info.dbname}\"\n",
    "vector_store = PGVector(connection=connection_string, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag.py\n",
    "\n",
    "import boto3\n",
    "from langchain_community.document_loaders import S3FileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag.py\n",
    "\n",
    "session = boto3.session.Session()\n",
    "client_s3 = session.client(\n",
    "    service_name=\"s3\",\n",
    "    endpoint_url=os.getenv(\"SCW_BUCKET_ENDPOINT\", \"\"),\n",
    "    aws_access_key_id=os.getenv(\"SCW_ACCESS_KEY\", \"\"),\n",
    "    aws_secret_access_key=os.getenv(\"SCW_SECRET_KEY\", \"\"),\n",
    ")\n",
    "paginator = client_s3.get_paginator(\"list_objects_v2\")\n",
    "page_iterator = paginator.paginate(Bucket=os.getenv(\"SCW_BUCKET_NAME\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_prompt(document_content, chunk_text):\n",
    "    \"\"\"\n",
    "    Creates a well-structured prompt for context generation.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_template = \"\"\"Here is the chunk we want to situate within the whole document \n",
    "<document>\n",
    "{document}\n",
    "</document>\n",
    "\n",
    "<chunk_to_analyze>\n",
    "{chunk}\n",
    "</chunk_to_analyze>\n",
    "Please give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk. Answer only with the succinct context and nothing else. \n",
    ".\"\"\"\n",
    "\n",
    "    return prompt_template.format(\n",
    "        document=document_content.strip(), chunk=chunk_text.strip()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<botocore.paginate.PageIterator at 0x15735c6d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrivee_scw/bienvenue.txt\n"
     ]
    }
   ],
   "source": [
    "# rag.py\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Initialize the client with your base URL and API key\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.scaleway.ai/v1\", api_key=os.getenv(\"SCW_SECRET_KEY\", \"\")\n",
    ")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=300,\n",
    "    add_start_index=True,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "for page in page_iterator:\n",
    "    for obj in page.get(\"Contents\", []):\n",
    "        if obj[\"Key\"] == \"arrivee_scw/bienvenue.txt\":\n",
    "            # Check if cursor is closed and reopen if necessary\n",
    "            if cur.closed:\n",
    "                cur = conn.cursor()\n",
    "\n",
    "            cur.execute(\n",
    "                \"SELECT object_key FROM object_loaded WHERE object_key = %s\",\n",
    "                (obj[\"Key\"],),\n",
    "            )\n",
    "            print(obj[\"Key\"])\n",
    "            response = cur.fetchone()\n",
    "            if response is None:\n",
    "                file_loader = S3FileLoader(\n",
    "                    bucket=os.getenv(\"SCW_BUCKET_NAME\", \"\"),\n",
    "                    key=obj[\"Key\"],\n",
    "                    endpoint_url=os.getenv(\"SCW_BUCKET_ENDPOINT\", \"\"),\n",
    "                    aws_access_key_id=os.getenv(\"SCW_ACCESS_KEY\", \"\"),\n",
    "                    aws_secret_access_key=os.getenv(\"SCW_SECRET_KEY\", \"\"),\n",
    "                )\n",
    "                file_to_load = file_loader.load()\n",
    "                doc = file_to_load[0].page_content\n",
    "                chunks = text_splitter.split_text(doc)\n",
    "                context_chunks = []\n",
    "\n",
    "                doc = \"Page title: \" + obj[\"Key\"] + \"\\n\" + doc\n",
    "\n",
    "                for chunk in chunks:\n",
    "                    \"\"\" completion = client.chat.completions.create(\n",
    "                        model=\"llama-3.1-8b-instruct\",\n",
    "                        messages=[\n",
    "                            {\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": create_context_prompt(\n",
    "                                    document_content=doc, chunk_text=chunk\n",
    "                                ),\n",
    "                            }\n",
    "                        ],\n",
    "                        temperature=0.1,\n",
    "                        max_tokens=100,\n",
    "                    ) \n",
    "                    print(completion.choices[0].message.content)\n",
    "                    context_chunks.append(completion.choices[0].message.content + chunk)\"\"\"\n",
    "                    context_chunks.append(chunk)\n",
    "\n",
    "                try:\n",
    "                    metadata_list = [\n",
    "                        {\n",
    "                            \"chunk_id\": idx,\n",
    "                            \"source\": obj[\"Key\"],\n",
    "                            \"timestamp\": datetime.now().isoformat(),\n",
    "                            \"chunk_size\": len(chunk),\n",
    "                            \"url\": \"https://confluence.infra.online.net/pages/viewpage.action?pageId=232395837\",\n",
    "                            # Add any other metadata fields you need\n",
    "                            \"position\": idx * len(chunk)\n",
    "                        }\n",
    "                        for idx, chunk in enumerate(context_chunks)\n",
    "                    ]\n",
    "                    embeddings_list = [\n",
    "                        embeddings.embed_query(chunk) for chunk in context_chunks\n",
    "                    ]\n",
    "                    vector_store.add_embeddings(chunks,embeddings=embeddings_list, metadatas=metadata_list)\n",
    "                    cur.execute(\n",
    "                        \"INSERT INTO object_loaded (object_key, metadata) VALUES (%s, %s)\",\n",
    "                        (obj[\"Key\"],json.dumps(metadata_list)),\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "class AnswerWithSources(TypedDict):\n",
    "    \"\"\"An answer to the question, with sources.\"\"\"\n",
    "\n",
    "    answer: str\n",
    "    sources: Annotated[\n",
    "        List[str],\n",
    "        ...,\n",
    "        \"List of sources (author + year) used to answer the question\",\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugophilipp/Documents/dev/tool-langgraph-llm/.venv/lib/python3.10/site-packages/langsmith/client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je ne sais pas quel lien est associé à \"Ultraviolet\"."
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "#rag.py\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "doc_list_1 = [\n",
    "    \"I like apples\",\n",
    "    \"I like oranges\",\n",
    "    \"Apples and oranges are fruits\",\n",
    "    \"\"\"🎨 Branding resources \n",
    "Ultraviolet provides with all the resources, guidelines, elements, and principles that are needed to create assets and communicate around our brand. It ensures consistency in how we present ourselves to the world and supports effective communication across our teams!\n",
    "\n",
    "\n",
    "  [Ultraviolet](https://ultraviolet.scaleway.com/6dd9b5c45/p/425c81-overview)\n",
    "\n",
    "Nos valeurs \n",
    "Singularité\n",
    "\n",
    "Nous sommes tous des êtres singuliers, nos équipes le sont aussi. Cette richesse qui fait notre force alimente notre aventure et façonne notre histoire.\"\"\"\n",
    "]\n",
    "\n",
    "# initialize the bm25 retriever and faiss retriever\n",
    "bm25_retriever = BM25Retriever.from_texts(\n",
    "    doc_list_1, metadatas=[{\"source\": 1}] * len(doc_list_1)\n",
    ")\n",
    "bm25_retriever.k = 2\n",
    "\n",
    "\n",
    "#rag.py\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        base_url=os.getenv(\"SCW_GENERATIVE_APIs_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"SCW_SECRET_KEY\"),\n",
    "        model=\"llama-3.1-8b-instruct\",\n",
    "        )\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "@chain\n",
    "def retriever(query: str) -> List[Document]:\n",
    "    docs, scores = zip(*vector_store.similarity_search_with_score(query))\n",
    "    for doc, score in zip(docs, scores):\n",
    "        doc.metadata[\"score\"] = score\n",
    "\n",
    "    return docs\n",
    "# retriever = vector_store.as_retriever()\n",
    "\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, retriever], weights=[0.5, 0.5]\n",
    ")\n",
    "ensemble_retriever = retriever\n",
    "rag_chain = (\n",
    "        {\"context\": ensemble_retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "for r in rag_chain.stream(\"Quelle est le lien de Ultraviolet ?\"):\n",
    "    print(r, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": ensemble_retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Le programme du premier jour est le suivant : Petit-déjeuner à 9h00, présentation par l'équipe IT Help Desk à 10h00, pause à 10h55, présentation de Scaleway et DRH à 11h00, tour des locaux et déjeuner avec ton manager à 12h00, et enfin présentation par l'équipe Product Management, Design et Product Documentation à 14h00.\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_with_source.invoke(\"Quelle est le programme du premier jour ?\")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata :  {'url': 'https://confluence.infra.online.net/pages/viewpage.action?pageId=232395837', 'source': 'arrivee_scw/bienvenue.txt', 'chunk_id': 1, 'position': 996, 'timestamp': '2024-10-24T11:06:04.504623', 'chunk_size': 996, 'score': 0.16478410854292203}\n",
      "metadata :  {'url': 'https://confluence.infra.online.net/pages/viewpage.action?pageId=232395837', 'source': 'arrivee_scw/bienvenue.txt', 'chunk_id': 1, 'position': 996, 'timestamp': '2024-10-24T11:01:39.043720', 'chunk_size': 996, 'score': 0.16478410854292203}\n",
      "metadata :  {'url': 'https://confluence.infra.online.net/pages/viewpage.action?pageId=232395837', 'source': 'arrivee_scw/bienvenue.txt', 'chunk_id': 1, 'position': 996, 'timestamp': '2024-10-24T11:00:13.865363', 'chunk_size': 996, 'score': 0.16478410854292203}\n",
      "metadata :  {'score': 0.18299622434355167}\n",
      "Le programme du premier jour, détaillé dans la section \"Ton premier jour\", comprend notamment un petit-déjeuner à 9h00, une présentation par l'équipe IT Help Desk à 10h00, une pause à 10h55, puis une présentation de Scaleway et de la DRH à 11h00, suivi d'un tour des locaux et d'un déjeuner avec le manager à 12h00, et enfin une présentation par l'équipe Product Management, Design et Product Documentation à 14h00."
     ]
    }
   ],
   "source": [
    "\n",
    "for chunk in rag_chain_with_source.stream(\"Quelle est le programme du premier jour ?\"):\n",
    "    if \"answer\" in chunk.keys() : \n",
    "        print (chunk[\"answer\"], end=\"\")\n",
    "\n",
    "    if \"context\" in chunk.keys() : \n",
    "        for e in chunk[\"context\"] :\n",
    "            print (\"metadata : \", e.metadata)\n",
    "\n",
    "    time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata fetching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
